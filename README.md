# Search-Engine-LLM
ğŸ” LangChain Search Engine with LLM

A Streamlit-powered Search Engine that combines the power of Groqâ€™s Llama3 Large Language Model (LLM) with LangChain tools.
This app allows you to query Wikipedia, ArXiv, and the Web (DuckDuckGo) simultaneously and get concise, contextual, and AI-enhanced results in real time.

<div align="center"> <img src="Screenshot%202025-08-20%20085718.png" alt="App Screenshot" width="900"/> </div>


âœ¨ Features

âœ… AI-Powered Search Engine â€“ Query multiple sources and get summarized answers.

âœ… Parallel Search Execution â€“ Wikipedia + ArXiv + Web results together.

âœ… Groq Llama3-8b-8192 â€“ Ultra-fast inference with streaming responses.

âœ… Interactive Chat UI â€“ Beautiful Streamlit-based chat-style interface.

âœ… Secure API Key Input â€“ Hide your Groq API key with password-type sidebar input.



ğŸ“Š Use Cases

ğŸ”¹ Students & Researchers â†’ Summarize research papers (ArXiv) quickly.

ğŸ”¹ Developers â†’ Fetch coding & ML concepts directly from Wikipedia/Web.

ğŸ”¹ General Knowledge â†’ Ask about celebrities, science, history, etc.

ğŸ”¹ AI Enthusiasts â†’ Learn how to build a LangChain-based Search Engine.



ğŸ› ï¸ Tech Stack

1. Frontend / UI â†’ Streamlit

2. LLM â†’ Groq Llama3-8b-8192

3. Framework â†’ LangChain

4. Search APIs â†’ Wikipedia, ArXiv, DuckDuckGo

5. Language â†’ Python 3.10+

   

ğŸ¯ Why Groq + LangChain + Streamlit?

âš¡ Groq â†’ Extremely fast inference with open-source Llama3.

ğŸ§  LangChain â†’ Agent-based orchestration with tool calling.

ğŸ¨ Streamlit â†’ Quick & elegant UI for LLM-based apps.
