# Search-Engine-LLM
🔎 LangChain Search Engine with LLM

A Streamlit-powered Search Engine that combines the power of Groq’s Llama3 Large Language Model (LLM) with LangChain tools.
This app allows you to query Wikipedia, ArXiv, and the Web (DuckDuckGo) simultaneously and get concise, contextual, and AI-enhanced results in real time.

<div align="center"> <img src="Screenshot%202025-08-20%20085718.png" alt="App Screenshot" width="900"/> </div>


✨ Features

✅ AI-Powered Search Engine – Query multiple sources and get summarized answers.

✅ Parallel Search Execution – Wikipedia + ArXiv + Web results together.

✅ Groq Llama3-8b-8192 – Ultra-fast inference with streaming responses.

✅ Interactive Chat UI – Beautiful Streamlit-based chat-style interface.

✅ Secure API Key Input – Hide your Groq API key with password-type sidebar input.



📊 Use Cases

🔹 Students & Researchers → Summarize research papers (ArXiv) quickly.

🔹 Developers → Fetch coding & ML concepts directly from Wikipedia/Web.

🔹 General Knowledge → Ask about celebrities, science, history, etc.

🔹 AI Enthusiasts → Learn how to build a LangChain-based Search Engine.



🛠️ Tech Stack

1. Frontend / UI → Streamlit

2. LLM → Groq Llama3-8b-8192

3. Framework → LangChain

4. Search APIs → Wikipedia, ArXiv, DuckDuckGo

5. Language → Python 3.10+

   

🎯 Why Groq + LangChain + Streamlit?

⚡ Groq → Extremely fast inference with open-source Llama3.

🧠 LangChain → Agent-based orchestration with tool calling.

🎨 Streamlit → Quick & elegant UI for LLM-based apps.
